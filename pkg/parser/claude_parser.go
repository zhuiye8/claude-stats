package parser

import (
	"bufio"
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"regexp"
	"strconv"
	"strings"
	"time"

	"github.com/zhuiye8/claude-stats/pkg/models"
)

// ClaudeParser ç”¨äºè§£æClaude JSONLæ—¥å¿—æ–‡ä»¶
type ClaudeParser struct {
	// é…ç½®é€‰é¡¹
	SkipErrors   bool
	Verbose      bool
	DateFilter   *DateFilter
}

// DateFilter ç”¨äºè¿‡æ»¤æ—¥æœŸèŒƒå›´
type DateFilter struct {
	StartDate *time.Time
	EndDate   *time.Time
}

// NewClaudeParser åˆ›å»ºæ–°çš„è§£æå™¨å®ä¾‹
func NewClaudeParser() *ClaudeParser {
	return &ClaudeParser{
		SkipErrors: true,
		Verbose:    false,
	}
}

// ParseDirectory è§£æç›®å½•ä¸­çš„æ‰€æœ‰JSONLæ–‡ä»¶
func (p *ClaudeParser) ParseDirectory(dirPath string) (*models.UsageStats, error) {
	stats := &models.UsageStats{
		ModelStats:   make(map[string]models.TokenUsage),
		DailyStats:   make(map[string]models.TokenUsage),
		SessionStats: make(map[string]models.SessionInfo),
		ProjectStats: make(map[string]models.ProjectStats),
		MessageTypes: make(map[string]int),
		DetectedMode: p.detectMode(dirPath),
	}

	err := filepath.Walk(dirPath, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		if strings.HasSuffix(strings.ToLower(info.Name()), ".jsonl") {
			if p.Verbose {
				fmt.Printf("ğŸ“‚ å¤„ç†æ–‡ä»¶: %s\n", path)
			}
			
			fileStats, err := p.ParseFile(path)
			if err != nil {
				if p.SkipErrors {
					fmt.Printf("âš ï¸  è·³è¿‡æ–‡ä»¶ %s: %v\n", path, err)
					return nil
				}
				return fmt.Errorf("è§£ææ–‡ä»¶ %s å¤±è´¥: %w", path, err)
			}

			p.mergeStats(stats, fileStats)
		}
		return nil
	})

	if err != nil {
		return nil, err
	}

	p.calculatePeriod(stats)
	p.calculateCost(stats)
	
	return stats, nil
}

// ParseFile è§£æå•ä¸ªJSONLæ–‡ä»¶
func (p *ClaudeParser) ParseFile(filePath string) (*models.UsageStats, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return nil, fmt.Errorf("æ‰“å¼€æ–‡ä»¶å¤±è´¥: %w", err)
	}
	defer file.Close()

	stats := &models.UsageStats{
		ModelStats:   make(map[string]models.TokenUsage),
		DailyStats:   make(map[string]models.TokenUsage),
		SessionStats: make(map[string]models.SessionInfo),
		ProjectStats: make(map[string]models.ProjectStats),
		MessageTypes: make(map[string]int),
	}

	scanner := bufio.NewScanner(file)
	// å¢åŠ æ‰«æå™¨ç¼“å†²åŒºå¤§å°ä»¥å¤„ç†é•¿è¡Œï¼ˆClaudeæ—¥å¿—å¯èƒ½åŒ…å«å¤§é‡ä»£ç ï¼‰
	maxCapacity := 10 * 1024 * 1024 // 10MB
	buf := make([]byte, maxCapacity)
	scanner.Buffer(buf, maxCapacity)
	lineNum := 0

	for scanner.Scan() {
		lineNum++
		line := strings.TrimSpace(scanner.Text())
		if line == "" {
			continue
		}

		entry, err := p.parseLine(line)
		if err != nil {
			if p.SkipErrors {
				if p.Verbose {
					fmt.Printf("âš ï¸  è¡Œ %d è§£æé”™è¯¯: %v\n", lineNum, err)
				}
				continue
			}
			return nil, fmt.Errorf("è¡Œ %d è§£æå¤±è´¥: %w", lineNum, err)
		}

		if entry != nil && p.shouldInclude(entry) {
			p.processEntry(stats, entry)
		}
	}

	if err := scanner.Err(); err != nil {
		return nil, fmt.Errorf("è¯»å–æ–‡ä»¶å¤±è´¥: %w", err)
	}

	return stats, nil
}

// parseLine è§£æå•è¡ŒJSONLå†…å®¹
func (p *ClaudeParser) parseLine(line string) (*models.ConversationEntry, error) {
	// å…ˆè§£æåˆ°mapä»¥å¤„ç†æœªçŸ¥å­—æ®µ
	var rawData map[string]interface{}
	if err := json.Unmarshal([]byte(line), &rawData); err != nil {
		return nil, fmt.Errorf("JSONè§£æå¤±è´¥: %w", err)
	}

	// åˆ›å»ºentryå¹¶è®¾ç½®åŸå§‹æ•°æ®
	entry := &models.ConversationEntry{
		RawData: rawData,
	}

	// æ‰‹åŠ¨æå–å­—æ®µä»¥é¿å…ç»“æ„ä¸åŒ¹é…é—®é¢˜
	if typeVal, ok := rawData["type"].(string); ok {
		entry.Type = typeVal
	}

	if sessionID, ok := rawData["sessionId"].(string); ok {
		entry.SessionID = sessionID
	}

	if uuid, ok := rawData["uuid"].(string); ok {
		entry.UUID = uuid
	}

	if parentUUID, ok := rawData["parentUuid"].(string); ok {
		entry.ParentUUID = parentUUID
	}

	if userType, ok := rawData["userType"].(string); ok {
		entry.UserType = userType
	}

	if cwd, ok := rawData["cwd"].(string); ok {
		entry.CWD = cwd
	}

	if version, ok := rawData["version"].(string); ok {
		entry.Version = version
	}

	if requestID, ok := rawData["requestId"].(string); ok {
		entry.RequestID = requestID
	}

	if summary, ok := rawData["summary"].(string); ok {
		entry.Summary = summary
	}

	if leafUUID, ok := rawData["leafUuid"].(string); ok {
		entry.LeafUUID = leafUUID
	}

	// å¤„ç†messageå­—æ®µ
	if messageData, ok := rawData["message"]; ok {
		entry.Message = messageData
		entry.ParsedMessage = p.parseMessage(messageData)
	}

	// æ‰‹åŠ¨å¤„ç†æ—¶é—´æˆ³ï¼Œæ”¯æŒå¤šç§æ ¼å¼
	if timestampStr, ok := rawData["timestamp"].(string); ok {
		timestamp, err := p.parseTimestamp(timestampStr)
		if err == nil {
			entry.Timestamp = timestamp
		}
	}

	// å°è¯•ä»æ¶ˆæ¯ä¸­æå–tokenä½¿ç”¨ä¿¡æ¯
	if entry.ParsedMessage != nil {
		entry.ExtractedUsage = p.extractTokenUsage(entry.ParsedMessage)
	}

	return entry, nil
}

// parseMessage è§£ææ¶ˆæ¯å†…å®¹
func (p *ClaudeParser) parseMessage(messageData interface{}) *models.ParsedMessage {
	parsedMsg := &models.ParsedMessage{}

	switch msg := messageData.(type) {
	case string:
		// å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è®¾ç½®ä¸ºcontent
		parsedMsg.Content = msg
		// å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–modelå’Œusageä¿¡æ¯
		parsedMsg.Model = p.extractModelFromString(msg)
		parsedMsg.Usage = p.extractUsageFromString(msg)
		
	case map[string]interface{}:
		// å¦‚æœæ˜¯å¯¹è±¡ï¼Œå°è¯•è§£æå„ä¸ªå­—æ®µ
		if role, ok := msg["role"].(string); ok {
			parsedMsg.Role = role
		}
		
		if content, ok := msg["content"]; ok {
			parsedMsg.Content = content
		}
		
		if model, ok := msg["model"].(string); ok {
			parsedMsg.Model = model
		}

		// å°è¯•è§£æusageä¿¡æ¯
		if usageData, ok := msg["usage"]; ok {
			parsedMsg.Usage = p.parseUsageFromInterface(usageData)
		}
		
		// å¦‚æœæ²¡æœ‰ç›´æ¥çš„usageå­—æ®µï¼Œå°è¯•ä»å…¶ä»–å­—æ®µæå–
		if parsedMsg.Usage == nil || parsedMsg.Usage.IsEmpty() {
			// æ£€æŸ¥æ˜¯å¦æœ‰tokenç›¸å…³çš„å­—æ®µ
			if tokenStr := p.extractStringFromMap(msg, []string{"tokens", "token_count", "usage_info"}); tokenStr != "" {
				parsedMsg.Usage = p.extractUsageFromString(tokenStr)
			}
		}
	}

	return parsedMsg
}

// extractModelFromString ä»å­—ç¬¦ä¸²ä¸­æå–æ¨¡å‹ä¿¡æ¯
func (p *ClaudeParser) extractModelFromString(content string) string {
	// å¸¸è§çš„Claudeæ¨¡å‹åç§°æ¨¡å¼
	modelPatterns := []string{
		`claude-3-5-sonnet-[0-9]+`,
		`claude-3-5-haiku-[0-9]+`,
		`claude-3-opus-[0-9]+`,
		`claude-3-sonnet-[0-9]+`,
		`claude-3-haiku-[0-9]+`,
		`claude-[0-9]+-[a-z]+-[0-9]+`,
	}

	for _, pattern := range modelPatterns {
		re := regexp.MustCompile(pattern)
		if match := re.FindString(content); match != "" {
			return match
		}
	}

	return ""
}

// extractUsageFromString ä»å­—ç¬¦ä¸²ä¸­æå–tokenä½¿ç”¨ä¿¡æ¯
func (p *ClaudeParser) extractUsageFromString(content string) *models.TokenUsage {
	usage := &models.TokenUsage{}
	
	// æŸ¥æ‰¾å„ç§tokenæ¨¡å¼
	patterns := map[string]*int{
		`"input_tokens":\s*(\d+)`:               &usage.InputTokens,
		`"output_tokens":\s*(\d+)`:              &usage.OutputTokens,
		`"cache_creation_input_tokens":\s*(\d+)`: &usage.CacheCreationTokens,
		`"cache_read_input_tokens":\s*(\d+)`:     &usage.CacheReadTokens,
		`input.*?(\d+).*?tokens`:                &usage.InputTokens,
		`output.*?(\d+).*?tokens`:               &usage.OutputTokens,
		`(\d+).*?input.*?tokens`:                &usage.InputTokens,
		`(\d+).*?output.*?tokens`:               &usage.OutputTokens,
	}

	for pattern, field := range patterns {
		re := regexp.MustCompile(pattern)
		if matches := re.FindStringSubmatch(content); len(matches) > 1 {
			if num, err := strconv.Atoi(matches[1]); err == nil && *field == 0 {
				*field = num
			}
		}
	}

	if usage.IsEmpty() {
		return nil
	}

	usage.TotalTokens = usage.GetTotalTokens()
	return usage
}

// parseUsageFromInterface ä»interface{}è§£æTokenUsage
func (p *ClaudeParser) parseUsageFromInterface(usageData interface{}) *models.TokenUsage {
	switch usage := usageData.(type) {
	case map[string]interface{}:
		tokenUsage := &models.TokenUsage{}
		
		if input, ok := usage["input_tokens"].(float64); ok {
			tokenUsage.InputTokens = int(input)
		}
		if output, ok := usage["output_tokens"].(float64); ok {
			tokenUsage.OutputTokens = int(output)
		}
		if cacheCreate, ok := usage["cache_creation_input_tokens"].(float64); ok {
			tokenUsage.CacheCreationTokens = int(cacheCreate)
		}
		if cacheRead, ok := usage["cache_read_input_tokens"].(float64); ok {
			tokenUsage.CacheReadTokens = int(cacheRead)
		}

		tokenUsage.TotalTokens = tokenUsage.GetTotalTokens()
		return tokenUsage
		
	case string:
		return p.extractUsageFromString(usage)
	}

	return nil
}

// extractStringFromMap ä»mapä¸­æå–å­—ç¬¦ä¸²å€¼
func (p *ClaudeParser) extractStringFromMap(data map[string]interface{}, keys []string) string {
	for _, key := range keys {
		if val, ok := data[key]; ok {
			if str, ok := val.(string); ok {
				return str
			}
		}
	}
	return ""
}

// extractTokenUsage ä»ParsedMessageä¸­æå–tokenä½¿ç”¨ä¿¡æ¯
func (p *ClaudeParser) extractTokenUsage(parsedMsg *models.ParsedMessage) *models.TokenUsage {
	// ä¼˜å…ˆä½¿ç”¨ç›´æ¥çš„Usageå­—æ®µ
	if parsedMsg.Usage != nil && !parsedMsg.Usage.IsEmpty() {
		return parsedMsg.Usage
	}

	// ä»Contentä¸­æå–
	if contentStr, ok := parsedMsg.Content.(string); ok {
		if usage := p.extractUsageFromString(contentStr); usage != nil {
			return usage
		}
	}

	// ä¼°ç®—tokenä½¿ç”¨é‡ï¼ˆåŸºäºæ–‡æœ¬é•¿åº¦çš„ç®€å•ä¼°ç®—ï¼‰
	if contentStr, ok := parsedMsg.Content.(string); ok && contentStr != "" {
		estimatedTokens := len(strings.Fields(contentStr)) / 3 * 4 // ç²—ç•¥ä¼°ç®—ï¼š4 tokens per 3 words
		if estimatedTokens > 0 {
			usage := &models.TokenUsage{}
			
			// æ ¹æ®è§’è‰²åˆ†é…input/output
			if parsedMsg.Role == "user" {
				usage.InputTokens = estimatedTokens
			} else if parsedMsg.Role == "assistant" {
				usage.OutputTokens = estimatedTokens
			} else {
				// å¦‚æœè§’è‰²ä¸æ˜ç¡®ï¼Œåˆ†æˆä¸€åŠä¸€åŠ
				usage.InputTokens = estimatedTokens / 2
				usage.OutputTokens = estimatedTokens - usage.InputTokens
			}
			
			usage.TotalTokens = usage.GetTotalTokens()
			return usage
		}
	}

	return nil
}

// parseTimestamp è§£ææ—¶é—´æˆ³ï¼Œæ”¯æŒå¤šç§æ ¼å¼
func (p *ClaudeParser) parseTimestamp(timestampStr string) (time.Time, error) {
	// æ”¯æŒçš„æ—¶é—´æ ¼å¼
	formats := []string{
		time.RFC3339,
		time.RFC3339Nano,
		"2006-01-02T15:04:05.000Z",
		"2006-01-02T15:04:05Z",
		"2006-01-02 15:04:05",
	}

	for _, format := range formats {
		if t, err := time.Parse(format, timestampStr); err == nil {
			return t, nil
		}
	}

	return time.Time{}, fmt.Errorf("æ— æ³•è§£ææ—¶é—´æˆ³: %s", timestampStr)
}

// shouldInclude æ£€æŸ¥æ¡ç›®æ˜¯å¦åº”è¯¥åŒ…å«åœ¨ç»Ÿè®¡ä¸­
func (p *ClaudeParser) shouldInclude(entry *models.ConversationEntry) bool {
	if p.DateFilter == nil {
		return true
	}

	if p.DateFilter.StartDate != nil && entry.Timestamp.Before(*p.DateFilter.StartDate) {
		return false
	}

	if p.DateFilter.EndDate != nil && entry.Timestamp.After(*p.DateFilter.EndDate) {
		return false
	}

	return true
}

// processEntry å¤„ç†å•ä¸ªæ¡ç›®ï¼Œæ›´æ–°ç»Ÿè®¡ä¿¡æ¯
func (p *ClaudeParser) processEntry(stats *models.UsageStats, entry *models.ConversationEntry) {
	stats.TotalMessages++
	
	// ç»Ÿè®¡æ¶ˆæ¯ç±»å‹
	if entry.Type != "" {
		stats.MessageTypes[entry.Type]++
	}

	// è°ƒè¯•ï¼šæ˜¾ç¤ºå‰å‡ æ¡è®°å½•çš„ç»“æ„
	if stats.TotalMessages <= 3 && p.Verbose {
		fmt.Printf("ğŸ” è°ƒè¯•ä¿¡æ¯ - è®°å½• #%d:\n", stats.TotalMessages)
		fmt.Printf("  Type: %s\n", entry.Type)
		
		model := ""
		if entry.ParsedMessage != nil {
			model = entry.ParsedMessage.Model
		}
		fmt.Printf("  Model: %s\n", model)
		
		fmt.Printf("  Usage: %+v\n", entry.ExtractedUsage)
		fmt.Printf("  RawDataå­—æ®µ: %v\n", getMapKeys(entry.RawData))
		
		if entry.ParsedMessage != nil {
			fmt.Printf("  ParsedMessage.Role: %s\n", entry.ParsedMessage.Role)
			if contentStr, ok := entry.ParsedMessage.Content.(string); ok && len(contentStr) > 50 {
				fmt.Printf("  Contenté¢„è§ˆ: %s...\n", contentStr[:50])
			}
		}
		fmt.Println("  ---")
	}

	// ç»Ÿè®¡è§£ææˆåŠŸçš„æ¶ˆæ¯
	if entry.ParsedMessage != nil {
		stats.ParsedMessages++
	}

	// å¤„ç†tokenä½¿ç”¨æƒ…å†µ
	if entry.ExtractedUsage != nil && !entry.ExtractedUsage.IsEmpty() {
		stats.ExtractedTokens++
		stats.TotalTokens.Add(*entry.ExtractedUsage)

		// æŒ‰æ¨¡å‹ç»Ÿè®¡
		model := ""
		if entry.ParsedMessage != nil && entry.ParsedMessage.Model != "" {
			model = entry.ParsedMessage.Model
		} else {
			model = "unknown" // é»˜è®¤æ¨¡å‹
		}
		
		modelUsage := stats.ModelStats[model]
		modelUsage.Add(*entry.ExtractedUsage)
		stats.ModelStats[model] = modelUsage

		// æŒ‰æ—¥æœŸç»Ÿè®¡
		dateKey := entry.Timestamp.Format("2006-01-02")
		dailyUsage := stats.DailyStats[dateKey]
		dailyUsage.Add(*entry.ExtractedUsage)
		stats.DailyStats[dateKey] = dailyUsage
	}

	// å¤„ç†ä¼šè¯ä¿¡æ¯
	if entry.SessionID != "" {
		session, exists := stats.SessionStats[entry.SessionID]
		if !exists {
			session = models.SessionInfo{
				ID:        entry.SessionID,
				StartTime: entry.Timestamp,
				EndTime:   entry.Timestamp,
				ProjectPath: entry.CWD,
			}
			if entry.ParsedMessage != nil && entry.ParsedMessage.Model != "" {
				session.Model = entry.ParsedMessage.Model
			}
			stats.TotalSessions++
		}

		session.MessageCount++
		if entry.Timestamp.After(session.EndTime) {
			session.EndTime = entry.Timestamp
		}
		if entry.Timestamp.Before(session.StartTime) {
			session.StartTime = entry.Timestamp
		}

		if entry.ExtractedUsage != nil {
			session.Tokens.Add(*entry.ExtractedUsage)
		}

		session.Duration = session.EndTime.Sub(session.StartTime).String()
		stats.SessionStats[entry.SessionID] = session
	}

	// å¤„ç†é¡¹ç›®ç»Ÿè®¡
	if entry.CWD != "" {
		projectKey := filepath.Base(entry.CWD)
		project, exists := stats.ProjectStats[projectKey]
		if !exists {
			project = models.ProjectStats{
				ProjectName: projectKey,
				ProjectPath: entry.CWD,
				LastActivity: entry.Timestamp,
			}
		}

		if entry.Timestamp.After(project.LastActivity) {
			project.LastActivity = entry.Timestamp
		}

		if entry.ExtractedUsage != nil {
			project.Tokens.Add(*entry.ExtractedUsage)
		}

		stats.ProjectStats[projectKey] = project
	}
}

// detectMode æ£€æµ‹ä½¿ç”¨æ¨¡å¼ï¼ˆAPI vs è®¢é˜…ï¼‰
func (p *ClaudeParser) detectMode(dirPath string) string {
	// ç®€å•å¯å‘å¼ï¼šæ£€æŸ¥æ˜¯å¦å­˜åœ¨costç›¸å…³ä¿¡æ¯
	// åœ¨çœŸå®å®ç°ä¸­ï¼Œè¿™é‡Œå¯ä»¥æœ‰æ›´å¤æ‚çš„é€»è¾‘
	return "subscription" // é»˜è®¤ä¸ºè®¢é˜…æ¨¡å¼ï¼Œå› ä¸ºå¤§å¤šæ•°ç”¨æˆ·ä½¿ç”¨è®¢é˜…
}

// mergeStats åˆå¹¶ç»Ÿè®¡æ•°æ®
func (p *ClaudeParser) mergeStats(target, source *models.UsageStats) {
	target.TotalMessages += source.TotalMessages
	target.TotalSessions += source.TotalSessions
	target.ParsedMessages += source.ParsedMessages
	target.ExtractedTokens += source.ExtractedTokens
	target.TotalTokens.Add(source.TotalTokens)

	// åˆå¹¶æ¨¡å‹ç»Ÿè®¡
	for model, usage := range source.ModelStats {
		targetUsage := target.ModelStats[model]
		targetUsage.Add(usage)
		target.ModelStats[model] = targetUsage
	}

	// åˆå¹¶æ—¥æœŸç»Ÿè®¡
	for date, usage := range source.DailyStats {
		targetUsage := target.DailyStats[date]
		targetUsage.Add(usage)
		target.DailyStats[date] = targetUsage
	}

	// åˆå¹¶ä¼šè¯ç»Ÿè®¡
	for sessionID, session := range source.SessionStats {
		target.SessionStats[sessionID] = session
	}

	// åˆå¹¶é¡¹ç›®ç»Ÿè®¡
	for projectKey, project := range source.ProjectStats {
		target.ProjectStats[projectKey] = project
	}

	// åˆå¹¶æ¶ˆæ¯ç±»å‹ç»Ÿè®¡
	for msgType, count := range source.MessageTypes {
		target.MessageTypes[msgType] += count
	}
}

// calculatePeriod è®¡ç®—åˆ†ææ—¶é—´æ®µ
func (p *ClaudeParser) calculatePeriod(stats *models.UsageStats) {
	var startTime, endTime time.Time
	first := true

	for _, session := range stats.SessionStats {
		if first {
			startTime = session.StartTime
			endTime = session.EndTime
			first = false
		} else {
			if session.StartTime.Before(startTime) {
				startTime = session.StartTime
			}
			if session.EndTime.After(endTime) {
				endTime = session.EndTime
			}
		}
	}

	if !first {
		stats.AnalysisPeriod = models.Period{
			StartTime: startTime,
			EndTime:   endTime,
			Duration:  endTime.Sub(startTime).String(),
		}
	}
}

// calculateCost è®¡ç®—æˆæœ¬
func (p *ClaudeParser) calculateCost(stats *models.UsageStats) {
	// ä½¿ç”¨Claude 3.5 Sonnetçš„å®šä»·ä½œä¸ºé»˜è®¤
	costCalculator := NewCostCalculator()
	stats.EstimatedCost = costCalculator.Calculate(&stats.TotalTokens, stats.ModelStats, stats.DetectedMode == "subscription")
}

// getMapKeys è·å–mapçš„æ‰€æœ‰é”®ï¼ˆè°ƒè¯•ç”¨ï¼‰
func getMapKeys(m map[string]interface{}) []string {
	keys := make([]string, 0, len(m))
	for k := range m {
		keys = append(keys, k)
	}
	return keys
} 