package parser

import (
	"bufio"
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"time"

	"github.com/zhuiye8/claude-stats/pkg/models"
)

// ClaudeParser ç”¨äºè§£æClaude JSONLæ—¥å¿—æ–‡ä»¶
type ClaudeParser struct {
	// é…ç½®é€‰é¡¹
	SkipErrors   bool
	Verbose      bool
	DateFilter   *DateFilter
}

// DateFilter ç”¨äºè¿‡æ»¤æ—¥æœŸèŒƒå›´
type DateFilter struct {
	StartDate *time.Time
	EndDate   *time.Time
}

// NewClaudeParser åˆ›å»ºæ–°çš„è§£æå™¨å®ä¾‹
func NewClaudeParser() *ClaudeParser {
	return &ClaudeParser{
		SkipErrors: true,
		Verbose:    false,
	}
}

// ParseDirectory è§£æç›®å½•ä¸­çš„æ‰€æœ‰JSONLæ–‡ä»¶
func (p *ClaudeParser) ParseDirectory(dirPath string) (*models.UsageStats, error) {
	stats := &models.UsageStats{
		ModelStats:   make(map[string]models.TokenUsage),
		DailyStats:   make(map[string]models.TokenUsage),
		SessionStats: make(map[string]models.SessionInfo),
		DetectedMode: p.detectMode(dirPath),
	}

	err := filepath.Walk(dirPath, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		if strings.HasSuffix(strings.ToLower(info.Name()), ".jsonl") {
			if p.Verbose {
				fmt.Printf("ğŸ“‚ å¤„ç†æ–‡ä»¶: %s\n", path)
			}
			
			fileStats, err := p.ParseFile(path)
			if err != nil {
				if p.SkipErrors {
					fmt.Printf("âš ï¸  è·³è¿‡æ–‡ä»¶ %s: %v\n", path, err)
					return nil
				}
				return fmt.Errorf("è§£ææ–‡ä»¶ %s å¤±è´¥: %w", path, err)
			}

			p.mergeStats(stats, fileStats)
		}
		return nil
	})

	if err != nil {
		return nil, err
	}

	p.calculatePeriod(stats)
	p.calculateCost(stats)
	
	return stats, nil
}

// ParseFile è§£æå•ä¸ªJSONLæ–‡ä»¶
func (p *ClaudeParser) ParseFile(filePath string) (*models.UsageStats, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return nil, fmt.Errorf("æ‰“å¼€æ–‡ä»¶å¤±è´¥: %w", err)
	}
	defer file.Close()

	stats := &models.UsageStats{
		ModelStats:   make(map[string]models.TokenUsage),
		DailyStats:   make(map[string]models.TokenUsage),
		SessionStats: make(map[string]models.SessionInfo),
	}

	scanner := bufio.NewScanner(file)
	lineNum := 0

	for scanner.Scan() {
		lineNum++
		line := strings.TrimSpace(scanner.Text())
		if line == "" {
			continue
		}

		entry, err := p.parseLine(line)
		if err != nil {
			if p.SkipErrors {
				if p.Verbose {
					fmt.Printf("âš ï¸  è¡Œ %d è§£æé”™è¯¯: %v\n", lineNum, err)
				}
				continue
			}
			return nil, fmt.Errorf("è¡Œ %d è§£æå¤±è´¥: %w", lineNum, err)
		}

		if entry != nil && p.shouldInclude(entry) {
			p.processEntry(stats, entry)
		}
	}

	if err := scanner.Err(); err != nil {
		return nil, fmt.Errorf("è¯»å–æ–‡ä»¶å¤±è´¥: %w", err)
	}

	return stats, nil
}

// parseLine è§£æå•è¡ŒJSONLå†…å®¹
func (p *ClaudeParser) parseLine(line string) (*models.ConversationEntry, error) {
	var entry models.ConversationEntry
	
	// å…ˆè§£æåˆ°mapä»¥å¤„ç†æœªçŸ¥å­—æ®µ
	var rawData map[string]interface{}
	if err := json.Unmarshal([]byte(line), &rawData); err != nil {
		return nil, fmt.Errorf("JSONè§£æå¤±è´¥: %w", err)
	}

	// è§£æåˆ°ç»“æ„ä½“
	if err := json.Unmarshal([]byte(line), &entry); err != nil {
		return nil, fmt.Errorf("ç»“æ„ä½“è§£æå¤±è´¥: %w", err)
	}

	entry.RawData = rawData

	// æ‰‹åŠ¨å¤„ç†æ—¶é—´æˆ³ï¼Œæ”¯æŒå¤šç§æ ¼å¼
	if timestampStr, ok := rawData["timestamp"].(string); ok {
		timestamp, err := p.parseTimestamp(timestampStr)
		if err == nil {
			entry.Timestamp = timestamp
		}
	}

	return &entry, nil
}

// parseTimestamp è§£ææ—¶é—´æˆ³ï¼Œæ”¯æŒå¤šç§æ ¼å¼
func (p *ClaudeParser) parseTimestamp(timestampStr string) (time.Time, error) {
	// æ”¯æŒçš„æ—¶é—´æ ¼å¼
	formats := []string{
		time.RFC3339,
		time.RFC3339Nano,
		"2006-01-02T15:04:05.000Z",
		"2006-01-02T15:04:05Z",
		"2006-01-02 15:04:05",
	}

	for _, format := range formats {
		if t, err := time.Parse(format, timestampStr); err == nil {
			return t, nil
		}
	}

	return time.Time{}, fmt.Errorf("æ— æ³•è§£ææ—¶é—´æˆ³: %s", timestampStr)
}

// shouldInclude æ£€æŸ¥æ¡ç›®æ˜¯å¦åº”è¯¥åŒ…å«åœ¨ç»Ÿè®¡ä¸­
func (p *ClaudeParser) shouldInclude(entry *models.ConversationEntry) bool {
	if p.DateFilter == nil {
		return true
	}

	if p.DateFilter.StartDate != nil && entry.Timestamp.Before(*p.DateFilter.StartDate) {
		return false
	}

	if p.DateFilter.EndDate != nil && entry.Timestamp.After(*p.DateFilter.EndDate) {
		return false
	}

	return true
}

// processEntry å¤„ç†å•ä¸ªæ¡ç›®ï¼Œæ›´æ–°ç»Ÿè®¡ä¿¡æ¯
func (p *ClaudeParser) processEntry(stats *models.UsageStats, entry *models.ConversationEntry) {
	stats.TotalMessages++

	// å¤„ç†tokenä½¿ç”¨æƒ…å†µ
	if entry.Usage != nil && !entry.Usage.IsEmpty() {
		stats.TotalTokens.Add(*entry.Usage)

		// æŒ‰æ¨¡å‹ç»Ÿè®¡
		if entry.Model != "" {
			modelUsage := stats.ModelStats[entry.Model]
			modelUsage.Add(*entry.Usage)
			stats.ModelStats[entry.Model] = modelUsage
		}

		// æŒ‰æ—¥æœŸç»Ÿè®¡
		dateKey := entry.Timestamp.Format("2006-01-02")
		dailyUsage := stats.DailyStats[dateKey]
		dailyUsage.Add(*entry.Usage)
		stats.DailyStats[dateKey] = dailyUsage
	}

	// å¤„ç†ä¼šè¯ä¿¡æ¯
	if entry.SessionID != "" {
		session, exists := stats.SessionStats[entry.SessionID]
		if !exists {
			session = models.SessionInfo{
				ID:        entry.SessionID,
				StartTime: entry.Timestamp,
				EndTime:   entry.Timestamp,
				Model:     entry.Model,
			}
			stats.TotalSessions++
		}

		session.MessageCount++
		if entry.Timestamp.After(session.EndTime) {
			session.EndTime = entry.Timestamp
		}
		if entry.Timestamp.Before(session.StartTime) {
			session.StartTime = entry.Timestamp
		}

		if entry.Usage != nil {
			session.Tokens.Add(*entry.Usage)
		}

		session.Duration = session.EndTime.Sub(session.StartTime).String()
		stats.SessionStats[entry.SessionID] = session
	}
}

// detectMode æ£€æµ‹ä½¿ç”¨æ¨¡å¼ï¼ˆAPI vs è®¢é˜…ï¼‰
func (p *ClaudeParser) detectMode(dirPath string) string {
	// ç®€å•å¯å‘å¼ï¼šæ£€æŸ¥æ˜¯å¦å­˜åœ¨costç›¸å…³ä¿¡æ¯
	// åœ¨çœŸå®å®ç°ä¸­ï¼Œè¿™é‡Œå¯ä»¥æœ‰æ›´å¤æ‚çš„é€»è¾‘
	return "subscription" // é»˜è®¤ä¸ºè®¢é˜…æ¨¡å¼ï¼Œå› ä¸ºå¤§å¤šæ•°ç”¨æˆ·ä½¿ç”¨è®¢é˜…
}

// mergeStats åˆå¹¶ç»Ÿè®¡æ•°æ®
func (p *ClaudeParser) mergeStats(target, source *models.UsageStats) {
	target.TotalMessages += source.TotalMessages
	target.TotalSessions += source.TotalSessions
	target.TotalTokens.Add(source.TotalTokens)

	// åˆå¹¶æ¨¡å‹ç»Ÿè®¡
	for model, usage := range source.ModelStats {
		targetUsage := target.ModelStats[model]
		targetUsage.Add(usage)
		target.ModelStats[model] = targetUsage
	}

	// åˆå¹¶æ—¥æœŸç»Ÿè®¡
	for date, usage := range source.DailyStats {
		targetUsage := target.DailyStats[date]
		targetUsage.Add(usage)
		target.DailyStats[date] = targetUsage
	}

	// åˆå¹¶ä¼šè¯ç»Ÿè®¡
	for sessionID, session := range source.SessionStats {
		target.SessionStats[sessionID] = session
	}
}

// calculatePeriod è®¡ç®—åˆ†ææ—¶é—´æ®µ
func (p *ClaudeParser) calculatePeriod(stats *models.UsageStats) {
	var startTime, endTime time.Time
	first := true

	for _, session := range stats.SessionStats {
		if first {
			startTime = session.StartTime
			endTime = session.EndTime
			first = false
		} else {
			if session.StartTime.Before(startTime) {
				startTime = session.StartTime
			}
			if session.EndTime.After(endTime) {
				endTime = session.EndTime
			}
		}
	}

	if !first {
		stats.AnalysisPeriod = models.Period{
			StartTime: startTime,
			EndTime:   endTime,
			Duration:  endTime.Sub(startTime).String(),
		}
	}
}

// calculateCost è®¡ç®—æˆæœ¬
func (p *ClaudeParser) calculateCost(stats *models.UsageStats) {
	// ä½¿ç”¨Claude 3.5 Sonnetçš„å®šä»·ä½œä¸ºé»˜è®¤
	costCalculator := NewCostCalculator()
	stats.EstimatedCost = costCalculator.Calculate(&stats.TotalTokens, stats.ModelStats, stats.DetectedMode == "subscription")
} 